{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7206484,"sourceType":"datasetVersion","datasetId":4169150}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Recognition model between Cats and Dogs\n$\\textrm{using Convolutional Neural Network (CNN) [Deep Learning]}$","metadata":{"id":"N2MHhpLovpKK"}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"lXiCk6ylwXII"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"id":"lytlZd9ZvHcx","execution":{"iopub.status.busy":"2023-12-15T19:19:44.039263Z","iopub.execute_input":"2023-12-15T19:19:44.039850Z","iopub.status.idle":"2023-12-15T19:19:44.045680Z","shell.execute_reply.started":"2023-12-15T19:19:44.039791Z","shell.execute_reply":"2023-12-15T19:19:44.044172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"id":"AqsTZg0C0SbX","outputId":"073f3f6e-7539-461d-ac96-d0ab5ac1b07b","execution":{"iopub.status.busy":"2023-12-15T19:19:44.048301Z","iopub.execute_input":"2023-12-15T19:19:44.048804Z","iopub.status.idle":"2023-12-15T19:19:44.065115Z","shell.execute_reply.started":"2023-12-15T19:19:44.048756Z","shell.execute_reply":"2023-12-15T19:19:44.063545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PART 1: Data Preprocessing","metadata":{"id":"dkYPx4qDxyyL"}},{"cell_type":"markdown","source":"### Preprocessing Training Set","metadata":{"id":"CAi5MbXs0pS6"}},{"cell_type":"code","source":"#Keras Libary for Image Preprocessing:\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n      #Divide all pixel values by 255. Hence all values lies b/w 0 to 1\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n#Importing Image from training Set\ntraining_set = train_datagen.flow_from_directory(\n        '/kaggle/input/cat-and-dog/Dataset/training_set',\n        target_size=(64,64),#Image Final Dimention which will be feed to model\n        batch_size=32,#Number of Images in each Batch\n        class_mode='binary')","metadata":{"id":"OJHdjmv60o1a","execution":{"iopub.status.busy":"2023-12-15T19:19:44.066777Z","iopub.execute_input":"2023-12-15T19:19:44.068143Z","iopub.status.idle":"2023-12-15T19:19:45.390095Z","shell.execute_reply.started":"2023-12-15T19:19:44.068103Z","shell.execute_reply":"2023-12-15T19:19:45.388847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Test Set","metadata":{"id":"sdoyigOb0ueo"}},{"cell_type":"code","source":"#Keras Libary for Image Preprocessing:\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n#Importing Image from test Set\ntest_set = test_datagen.flow_from_directory(\n    '/kaggle/input/cat-and-dog/Dataset/test_set',\n    target_size = (64, 64),#Image Final Dimention which will be feed to model\n    batch_size = 32,#Number of Images in each Batch\n    class_mode = 'binary')","metadata":{"id":"ah2ikMOS0zCR","execution":{"iopub.status.busy":"2023-12-15T19:19:45.393225Z","iopub.execute_input":"2023-12-15T19:19:45.394138Z","iopub.status.idle":"2023-12-15T19:19:45.475431Z","shell.execute_reply.started":"2023-12-15T19:19:45.394086Z","shell.execute_reply":"2023-12-15T19:19:45.474103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PART 2: Building the CNN","metadata":{"id":"dKjmIhlY_lJe"}},{"cell_type":"markdown","source":"### Initialising the CNN","metadata":{"id":"A4OxIGXo_7If"}},{"cell_type":"code","source":"cnn=tf.keras.models.Sequential()","metadata":{"id":"8RS3khyA_t1t","execution":{"iopub.status.busy":"2023-12-15T19:19:45.476877Z","iopub.execute_input":"2023-12-15T19:19:45.477219Z","iopub.status.idle":"2023-12-15T19:19:45.485755Z","shell.execute_reply.started":"2023-12-15T19:19:45.477190Z","shell.execute_reply":"2023-12-15T19:19:45.484668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 1 - Convolution\n\n$\\textrm{Input Image}→\\text{Feature Maps}→\\text{Apply reLU{Rectifier Function}}$\n\nApplying **Filters/Feture Dectectors** on Original Image to get **Convolation Layes/Feature Map**","metadata":{"id":"JLEr-a6BBNQS"}},{"cell_type":"code","source":"# Adding Convolutional Layer\ncnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))","metadata":{"id":"MOeOS1_4CnYW","execution":{"iopub.status.busy":"2023-12-15T19:19:45.487468Z","iopub.execute_input":"2023-12-15T19:19:45.487962Z","iopub.status.idle":"2023-12-15T19:19:45.516924Z","shell.execute_reply.started":"2023-12-15T19:19:45.487914Z","shell.execute_reply":"2023-12-15T19:19:45.515675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2 - Pooling\n$\\textrm{Input Image}→\\text{Feature Maps}→\\text{Apply reLU{Rectifier Function}}→\\text{Pooled Featured Layer}$\n\nApplying **Filters/Feture Dectectors** on Original Image to get **Convolation Layes/Feature Map** and from that we extract main Features of image leaving useless data which generate **Pooled Featured Layer** {mostly we use Max-Pooling}","metadata":{"id":"7YOwC0B5Hb6r"}},{"cell_type":"code","source":"# Adding Pooling Layer\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))","metadata":{"id":"WRFDDNURMKk0","execution":{"iopub.status.busy":"2023-12-15T19:19:45.518535Z","iopub.execute_input":"2023-12-15T19:19:45.519112Z","iopub.status.idle":"2023-12-15T19:19:45.530893Z","shell.execute_reply.started":"2023-12-15T19:19:45.519066Z","shell.execute_reply":"2023-12-15T19:19:45.529458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding Secound Convolutional and Pooling Layer\n{for better processing of feature and better result from image}","metadata":{"id":"zWS6dBFpS_J1"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))","metadata":{"id":"Tyx_wcRbTIC2","execution":{"iopub.status.busy":"2023-12-15T19:19:45.532713Z","iopub.execute_input":"2023-12-15T19:19:45.533171Z","iopub.status.idle":"2023-12-15T19:19:45.562602Z","shell.execute_reply.started":"2023-12-15T19:19:45.533118Z","shell.execute_reply":"2023-12-15T19:19:45.561097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3 - Flattening\n$\\textrm{Input Image}→\\text{Feature Maps}→\\text{Apply reLU{Rectifier Function}}→\\text{Pooled Featured Layer}→\\text{Flattened}$\n\nApplying **Filters/Feture Dectectors** on Original Image to get **Convolation Layes/Feature Map** and from that we extract main Features of image leaving useless data which generate **Pooled Featured Layer** {mostly we use Max-Pooling}.\n\nThis Pooled Featured Layer is in non-UniDimensional array which can be used in input of main Processing of ANN. Hence, We convert it into 1D array[0,1,2,3...n] for processing of ANN. Hence, This Process is known as **Flattening**","metadata":{"id":"mOfAFbySTddJ"}},{"cell_type":"code","source":"# Adding Pooling Layer\ncnn.add(tf.keras.layers.Flatten())","metadata":{"id":"RK-DksjAUtBQ","execution":{"iopub.status.busy":"2023-12-15T19:19:45.564328Z","iopub.execute_input":"2023-12-15T19:19:45.564708Z","iopub.status.idle":"2023-12-15T19:19:45.577616Z","shell.execute_reply.started":"2023-12-15T19:19:45.564675Z","shell.execute_reply":"2023-12-15T19:19:45.576409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4 - Fully Connection","metadata":{"id":"KZgbmtpmXRjc"}},{"cell_type":"code","source":"#Hidden Layer\ncnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n\n#Output layer\ncnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n\n#'activation='softmax' {for classfication output}","metadata":{"id":"ADZTImyJXct1","execution":{"iopub.status.busy":"2023-12-15T19:19:45.582788Z","iopub.execute_input":"2023-12-15T19:19:45.583188Z","iopub.status.idle":"2023-12-15T19:19:45.623006Z","shell.execute_reply.started":"2023-12-15T19:19:45.583147Z","shell.execute_reply":"2023-12-15T19:19:45.621878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PART 3: Training The CNN","metadata":{"id":"yWHMj9ZBZ3Mr"}},{"cell_type":"markdown","source":"### Compiling CNN","metadata":{"id":"9tGhHomWZ8dK"}},{"cell_type":"code","source":"cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"id":"6ZTBrhQUaHRB","execution":{"iopub.status.busy":"2023-12-15T19:19:45.625944Z","iopub.execute_input":"2023-12-15T19:19:45.626673Z","iopub.status.idle":"2023-12-15T19:19:45.643649Z","shell.execute_reply.started":"2023-12-15T19:19:45.626621Z","shell.execute_reply":"2023-12-15T19:19:45.642139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training CNN Model\nTraining the CNN on Training Set and evaluating it on Test Set","metadata":{"id":"WMKs5AxiaNjX"}},{"cell_type":"code","source":"cnn.fit(x=training_set,validation_data=test_set,epochs=25)","metadata":{"id":"SriGDzIBas82","execution":{"iopub.status.busy":"2023-12-15T19:19:45.645149Z","iopub.execute_input":"2023-12-15T19:19:45.645522Z","iopub.status.idle":"2023-12-15T19:50:06.091317Z","shell.execute_reply.started":"2023-12-15T19:19:45.645488Z","shell.execute_reply":"2023-12-15T19:50:06.090217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:50:06.092885Z","iopub.execute_input":"2023-12-15T19:50:06.093203Z","iopub.status.idle":"2023-12-15T19:50:06.126715Z","shell.execute_reply.started":"2023-12-15T19:50:06.093176Z","shell.execute_reply":"2023-12-15T19:50:06.125690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.save('image_reco_2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:50:06.128078Z","iopub.execute_input":"2023-12-15T19:50:06.128407Z","iopub.status.idle":"2023-12-15T19:50:06.183265Z","shell.execute_reply.started":"2023-12-15T19:50:06.128379Z","shell.execute_reply":"2023-12-15T19:50:06.182038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 4: Predictions","metadata":{"id":"gge8c6nVdB7y"}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom keras.utils import load_img,img_to_array\ndef finder(address_of_img:str)->bool:\n  test_img=load_img(address_of_img,target_size=(64,64))\n  test_img=img_to_array(test_img)#as CNN expect 2D array\n  test_img=np.expand_dims(test_img,axis=0) #add fake dimentions\n  result=cnn.predict(test_img)\n  training_set.class_indices\n  return('Dog' if result else 'Cat')","metadata":{"id":"5JC7-TAHdBe4","execution":{"iopub.status.busy":"2023-12-15T19:50:06.185348Z","iopub.execute_input":"2023-12-15T19:50:06.185839Z","iopub.status.idle":"2023-12-15T19:50:06.194598Z","shell.execute_reply.started":"2023-12-15T19:50:06.185795Z","shell.execute_reply":"2023-12-15T19:50:06.193025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dog image\nimage_path='/kaggle/input/cat-and-dog/Dataset/prediction/test_1.jpg'\n\nimg = cv2.imread(image_path)\n# Convert BGR image to RGB\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Display the image with a title indicating whether it's a cat or a dog\nplt.imshow(img_rgb)\nplt.title(finder(image_path))\nplt.show()","metadata":{"id":"qslE83cbp-fs","execution":{"iopub.status.busy":"2023-12-15T19:50:06.196656Z","iopub.execute_input":"2023-12-15T19:50:06.197360Z","iopub.status.idle":"2023-12-15T19:50:07.036288Z","shell.execute_reply.started":"2023-12-15T19:50:06.197313Z","shell.execute_reply":"2023-12-15T19:50:07.034991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cat image\nimage_path = '/kaggle/input/cat-and-dog/Dataset/prediction/test_2.jpg'\n\nimg = cv2.imread(image_path)\n# Convert BGR image to RGB\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Display the image with a title indicating whether it's a cat or a dog\nplt.imshow(img_rgb)\nplt.title(finder(image_path))\nplt.show()","metadata":{"id":"sZhqy4NY4D8m","execution":{"iopub.status.busy":"2023-12-15T19:50:07.037815Z","iopub.execute_input":"2023-12-15T19:50:07.038353Z","iopub.status.idle":"2023-12-15T19:50:07.436926Z","shell.execute_reply.started":"2023-12-15T19:50:07.038305Z","shell.execute_reply":"2023-12-15T19:50:07.435742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}